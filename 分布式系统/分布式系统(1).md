# 分布式系统（1）

## 分布式理论基础

### CAP理论

- C（Consistency）：一致性 

  一个写操作返回成功，那么之后的读请求都必须读到这个新数据；如果返回失败，那么所有读操作都不能读到这个数据。所有节点访问同一份最新的数据。

- A（Availability）：可用性

  对数据更新具备高可用性，请求能够及时处理，不会一直等待，即使出现节点失效。

- P（Partition tolerance）：分区容错性

  能容忍网络分区，在网络断开的情况下，被分隔的节点仍能正常对外提供服务。

三者不能同时满足，最多只能满足其中两个。

### BASE理论

- Basically Available（基本可用）

  分布式系统在出现不可预知故障的时候，允许损失部分可用性。

- Soft state（软状态）

  软状态也称为弱状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。

- Eventually consistent（最终一致性）

  最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。



## Paxos,Raft,ZAB的差异对比

### Leader选举

#### Raft

https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md

#### ZAB

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/986d18bd167e4a408e1be37c6063635a.png)

##### 开始阶段

先把票箱清理干净，然后填充选票内容，分别填充以下内容：

1. 所推举的`Leader id`：在初始阶段，第一次投票所有Server都推举自己为Leader。
2. 所推举节点上最大`zxid`值：这个值越大，说明该Server的数据越新
3. `round`：这个值从0开始递增，每次选举对应一个值，即在同一次选举中，这个值是一致的。这个值越大说明选举进程越新。
4. `state`：包括LOOKING，FOLLOWING，OBSERVING，LEADING

然后把填充的选票发送给其他所有对等的节点

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/3eb03ae59f41c5493b994d66c3e3c425.png)

该图描述了收到选票时的行为，也就是如果本节点处于`Election`，就把此投票push到`P.queue`中。如果本节点的`Round`大于对端，还要发送一个本端的投票信息。

下面一个判断其实就是正常的ACK了，也就是我现在不是`Election`，但是有`Election`的大哥给我发送消息，那我告诉你我的配置好了。

##### 处理选票

此时所有收到的选票信息放在P.queue中，从其中一个一个取，如果没有的话，就超时重传喽。

如果发送此选票的结点状态为`Election`：

1. 如果发送过来的round大于目前的round。说明这是更新的一次选举，需要更新本机的round，同时清空已经收集到的选票，因为这些数据已经不再有效。然后判断是否需要更新自己的选举情况。首先判断zxid，zxid大者胜出；如果相同比较leader id，大者胜出。当然更新了信息就意味这此节点目前把票投给了这个更新的结点，其他结点接收到后会不出意外会更新票箱。
2. 如果发送过来的round等于目前的round。根据收到的zxid和leader id更新选票，然后广播出去。
3. 如果发送过来的round小于于目前的round。说明对方处于一个比较早的选举进程，只需要将本机的数据发送过去即可。

把经过上面处理的票信息放入票箱。接下来根据已有数据更新：

1. 判断票箱信息是否等于SizeEnsemble，也就是服务器是否已经收集到所有的服务器的选举状态，此时可以做出判断。根据选举结果设置自己的角色（FOLLOWING or LEADER），然后退出选举。
2. 如果没有收到没有所有服务器的选举状态，也可以判断一下根据以上过程之后更新的选举Leader是不是得到了超过半数以上服务器的支持。如果是，那么尝试在 T0 ms内接收下数据，如果没有新数据到来说明大家已经认同这个结果。这时，设置角色然后退出选举。

当然发送选票的结点状态也可能是leader或者follower

> 某个分区结束（可能很短，可能很长）的Leader或者Follower，此时请求投票可以看到对方为Leader或者Follower

首先判断round是否相同，是的话将数据保存到票箱，然后进行如下判断：

1. 如果发送者宣称自己是Leader，直接更改状态为Follower。
2. 如果发送者宣称自己是Follower，那么判断是不是半数以上的服务器都选举它，如果是设置角色并退出选举。

如果再走到下面的逻辑判断，说明这是一条与当前接收结点Round不符合的消息，当然有可能是更高的Round，也可能是更低的Round。

如果对端的投票指向自己，且OutOfElection中存在着半数的选票指向自己，此时晋升。

> Raft与ZAB在选举阶段的不同之处：
>
> 1. `Raft`选举时每个`Follower`只持有投向自己的选票；`Fast Leader Election`每个`Follower`持有所有结点的投票信息，并可基于此做判断。
> 2. 结点在收到一个更大的选票时会修改并广播自己的选票，且基于已接收结点的选票作为选主标准，只有zxid以及id组合最大的结点可以成为Leader；而Raft相比之下就简单的多，只有在对端日志以及Term均大于自己时才会投票，基于得到的票数选主。两者均保证日志最新的结点选举成功。
> 3. `Raft`每个`Term`只能投票一次；而`Fast Leader Election`可以在一个`Epoch`内更改选票。

为什么`Fast Leader Election`比一般的`Leader Election`更快，基本上能搜到的答案就是短短一句话：

> `FastLeaderElection`选举算法是标准的`Fast Paxos`算法复现，可解决`Leader Election`选举算法收敛速度慢的问题。

#### Paxos

- 多个Leader，但不会影响正确性

  <img src="https://i-blog.csdnimg.cn/blog_migrate/af2668f2bf7fbccf732f73177c226c29.png" alt="在这里插入图片描述" style="zoom: 25%;" />

- 一个Leader，基于租约选举

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/c01b5bc39198ca0f819ec3e5f4a01413.png)

其实就是把成为Leader的消息看做是一条日志，让Paxos保证一致，这也可以看出这种选举方法其实和Paxos是完全解耦合的。

具体的过程就是：

1. 把BeMaster看做是一个Proposer操作，其中携带自己的节点信息。

2. 状态机中的callback做两件事情，第一：发现Value的节点非自己，则等待timeout时间再发起BeMaster。第二：发现Value的节点是自己，那么将自己提升为Master，并在T(BeMaster) + timeout后过期。

通过以上我们可以看出显然基于租约的选举同一时刻最多只能有一个结点为Leader，但是不保证这个Leader拥有最新日志，

### 选举信息

`Fast Leader Election`的选举请求信息为`(P.vote,P.id,P.state,P.round)`，`P.vote←（P.lastZxid,P.id）`

而Raft为`(term,candidateId,lastLogIndex,lastLogTerm)`

Paxos为`accept(n,v,index,firstUnchoosenIndex)`

### 选举的触发

对于Raft和ZAB来说，其实就是超时后触发超时事件，进行新一轮选举，但是Raft只有Follower可以发起选举；ZAB则是Leader和Follower都可以发起选举。

leader和follower都有各自的检测超时方式，leader是检测是否过半follower心跳回复了，follower检测leader是否发送心跳了。

一旦leader检测失败，则leader进入LOOKING状态，其他follower过一段时间因收不到leader心跳也会进入LOOKING状态，从而出发新的leader选举。

一旦follower检测失败了，则该follower进入LOOKING状态，此时如果leader和其他follower仍然保持良好，则该follower仍然是去学习上述leader的投票，而不是触发新一轮的leader选举；反之则是触发新一轮选举。

至于Paxos，则是与选举算法有关，本文呈现的两种方法对应了两种不同的选举触发条件，一个是检测到自己的ID最大的时候；基于租约的选举则是在超时之后进行选举，其实就是去进行一轮Base-Paxos。

### 上一轮次的数据

#### 如何处理上一轮未提交的日志

这是一个非常有意思的问题，话说的再清楚一点就是如何处理上一轮未达成一致的日志，其实这个问题与协议本身无关，而与应用有关，因为无论怎么处理，其实从协议的角度来说都是可以达成一致的。但是对应用就不一样了，处理的策略不妥可能会出现一种称为“幽灵复现”的问题。

问题的本质就是分布式系统中复杂的根源所在，即“第三态”问题，分布式系统中RPC请求存在三种情况，成功，失败与超时。在超时时要求后面每一次读取可以看到上一次读取结果。这其实很不好搞。拿Raft举个例子：

假设存在如下日志：

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/d25fd6ed3b04bd621516a1552fcd5f94.png)

1. A节点为leader，Log entry 5，6内容还没有commit，A节点发生宕机。这个时候client 无法查询到 Log entry 5，6里面的内容。
2. B成为Leader, B中Log entry 3, 4内容复制到C中（心跳包）， 并且在B为主的期间内没有写入任何内容。
3. A 恢复并且B、C发生重启，A又重新选为leader, 那么Log entry 5, 6内容又被复制到B和C中，这个时候client再查询就查询到Log entry 5, 6 里面的内容了。

这就是一个幽灵复现的场景，比如客户刚刚买了个手机，返回超时，然后查一下购买记录发现购买没有成功，客户大概率会重新购买一次，这样在后面的Term中就会存在两条购买记录，客户一定不希望看到这种情况。

对于Raft来说只需要在Leader选举成功后写入一条空日志（需要被Commit）就好了，这样的话就不会出现上述问题了。

一般过程中Raft如何对待上一Term的日志呢？

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/15d51ae6bf09b2c4f5925401ab827cf2.png)

其实就是不提交，就算已经拷贝到了大多数结点上也不会提交，除非在Term内也提交了一条日志，上一条日志才会被顺带提交，也就是上图中的（e）。

ZAB协议的解决思路不太一样。我们还是拿上面的图：

<img src="https://i-blog.csdnimg.cn/blog_migrate/1c58f3073408d1e185a6c06ddfb694ff.png" alt="在这里插入图片描述" style="zoom:50%;" />

首先A的Log entry 5，6没有被提交，A宕机。假设B晋升，但是没有写入任何一条Log entry，意味着B的最后一条日志zxid依然小于A的最后一条日志的zxid，如果A恢复，就会重新称为Leader，此时会在Recovery同步数据，从而出现幽灵复现的问题，解决的思路就是持久化CurrentEpoch，在请求选举时带上CurrentEpoch，这样就没有这个问题了。

ZAB如何对待上一Term的日志呢？采取激进的策略，对于所有过半还是未过半的日志都判定为提交，都将其应用到状态机中。

至于Paxos如何避免，这个牵扯到日志，所以我们先不谈。

### 脑裂问题

脑裂（split-brain）问题其实就是说集群中可能会出现两个主结点，事实上Raft和ZAB在正常情况下不会出现这个问题，因为只有在获得大于二分之一结点数量的同意时操作才有效，虽然分区可能使得出现多个主，但是其中最多有一个可以工作。

Paxos允许多主，且在多主情况下仍保证正确性，这主要是由Base-Paxos来实现的，多主可以并发写入，不过可能会出现活锁问题。

Paxos的这个特性让我觉得整个Multi-paxos就类似于一个P2P网络！

所有节点互相双向同步，对所有unchoose的日志进行不断确认的过程（反熵的过程）！！这个网络中，可以出现多个leader，可能出现多个leader来回切换，这都不影响正确性。

### 请求处理过程

Raft和Paxos选择在各种交互的包中放入最后一条被提交日志的下标，以此同步日志。而ZAB则会向所有的follower发送一个提交日志的请求，同时leader自己也会提交该提案，应用到状态机中，完毕后回复客户端。

### 日志的连续性

Raft的日志是连续的（日志匹配原则），这使得Leader在拥有最新的日志时也拥有了最全的日志，也就是在Raft中数据的流向是单向的，即从Leader到Follower，这使得整个过程非常简单，且易于理解。

而Paxos的日志是不连续的，因为因为当前leader再上一任leader的任期内可能错过了一些日志的同步，而这些日志在其他机器上形成多了多数派。由于logID连续递增，被错过的日志就成了连续logID连续递增序列中的“空洞”，需要通过重确认来补全这些“空洞”位置的日志。而每一次重确认其实都需要一轮完整的Paxos过程。

可能有些日志在恢复前确实未形成多数派备份，需要通过重新执行Paxos来把这些日志重新持久化才能回放。这种不管日志是否曾经形成多数派备份，都重新尝试持久化的原则，这被称为“最大commit原则”，这是因为在持有日志的结点宕机是我们没办法区分某个日志是否已经被提交。

当然这也可能造成幽灵复现问题，可以使用epochID，提交日志时如果上一条Log entry epochID大于本条（为了防止两个leader，选主成功时会执行一条StartWorking日志，所以本epoch必定有新日志，以此拒绝幽灵日志），证明本条是幽灵日志。

