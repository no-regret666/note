# 消息队列（`MQ`）

## 消息中间件执行原理

### 1 关于消息中间件

#### 1.1 什么是消息中间件

消息中间件是指在分布式系统中完成消息的发送和接收的基础软件。

消息中间件也可以称消息队列（Message Queue / `MQ`），用高效可靠的消息传递机制进行与平台无关的数据交流，并基于数据通信来进行分布式系统的集成。通过提供消息传递和消息队列模型，可以在分布式环境下扩展进程的通信。

简而言之，**互联网场景中经常使用消息中间件进行消息路由、订阅发布、异步处理等操作，来缓解系统的压力**。

#### 1.2 解决痛点

1. 解耦
2. 有序性
3. 消息路由
4. 异步处理
5. 削峰

### 2 消息中间件的执行原理

#### 2.1 消息中间件的组成

- Broker：消息服务器，作为Server提供消息核心服务
- Producer：消息生产者，业务的发起方，负责生产信息传输给broker
- Consumer：消息消费者，业务的处理方，负责从broker获取消息并进行业务逻辑处理
- Topic：主题，发布/订阅模式下的消息统一汇集地，不同生产者向topic发送消息，由`MQ`服务器分发到不同的订阅者，实现消息的广播
- Queue：队列，`PTP`模式下，特定生产者向特定queue发送消息，消费者订阅特定的queue完成指定消息的接收
- Message：消息体，根据不同通信协议定义的固定格式进行编码的数据包，来封装业务数据，实现消息的传输

#### 2.2 消息中间件的模式分类

1. PTP点对点
2. Pub/Sub发布订阅（广播）

#### 2.3 消息中间件的优势       

- **系统解耦**
- **消峰、提高系统响应时间**
- **业务的有序性处理**
- **为大数据处理架构提供服务**

#### 2.4 消息中间件常用协议

AMQP协议、MQTT协议、STOMP协议、XMPP协议、其他基于TCP/IP自定义的协议消息中间件的组成



### 高可用性

#### `RabbitMQ`的高可用性

1. 单击模式

   demo级别

2. 普通集群模式

   - 队列元数据共享，消息不共享：

     队列的元数据（如队列的名称、属性等）会在集群中的所有节点间同步。

     队列中的消息只存储在队列所在的主节点上，其他节点不会同步这些消息。

     如果消费者访问队列的非主节点，消息会通过 RabbitMQ 的内部通信机制从主节点拉取到消费者。

   - 节点之间通信依赖网络：

     消息的传输依赖网络通信，若主节点出现问题，相关队列的消息将不可用。

   - 扩展性较好：

     节点之间只同步队列的元数据，而不复制消息内容，通信开销较小，可以支持更大的集群规模。

3. 镜像集群模式

   - 队列和消息全量同步：

     队列的元数据和消息会同步到所有的镜像节点。

     消息的副本存储在多个节点上，保证了队列的高可用性。

   - 主从架构：

     每个队列都有一个主节点和多个镜像节点。

     消费者从主节点消费消息，镜像节点实时同步主节点的数据。

   - 故障切换：

     如果主节点宕机，RabbitMQ 会自动将镜像节点提升为主节点，继续对外提供服务（需要依赖集群管理机制）。



### 消息幂等性

#### 1 介绍

我们实际系统中有很多操作，不管你执行多少次，都应该产生一样的效果或返回一样的结果。这需要幂等的特性来支持。

幂等是一个数学与计算机学概念，常见于抽象代数中。在编程中，一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。

#### 2 消息队列中如何保证幂等性

1. 先查再保存，每次保存数据的时候，都先查一下，如果数据存在了那么就不保存。这个情况是并发不高的情况。
2. 业务表添加约束条件，如果你的数据库将来都不会分库分表，那么可以在业务表字段加上唯一约束条件（UNIQUE），这样相同的数据就不会保存为多份
3. 添加消息表，在数据库里面，添加一张消息消费记录表，表字段加上唯一约束条件（UNIQUE），消费完之后就往表里插入一条数据。因为加了唯一约束条件，第二次保存的时候，mysql 就会报错，就插入不进去；通过数据库可以限制重复消费。
4. 使用 redis 如果你的系统是分布式的，又做了分库分表，那么可以使用 redis 来做记录，把消息 id 存在 redis 里，下次再有重复消息 id 在消费的时候，如果发现 redis 里面有了就不能进行消费。
5. 高并发下 如果你的系统并发很高，那么可以使用 redis 或者 zookeeper 的分布式对消息 id 加锁，然后使用上面的几个方法进行幂等性控制。



### 可靠性

#### 1 消息生产阶段

消息生产阶段指的是消息从生产到消息发送出去，经过网络传输，再到达Broker服务器并被接收的这整个阶段，我们需要一个健壮的确认机制（ACK）来保证消息传递的可靠性。如果说消息被接收到之后可以反馈给消息生产方去确认，那这个过程就比较完美了。

- 消息创建和发送事务性原则保证，要么成功，要么不成功
- 同步发送时，处理好返回值，如果发生异常，则进行异常捕捉并处理。
- 异步发送时，处理好回调的工作，如果发生异常，则进行异常捕捉并处理。
- 异常/超时重试机制：如果长时间收不到确认返回结果，则需要进行重试；如果返回的结果是异常的，也可以有限的进行重试。
- 超时重试和异常重试需要谨慎使用，重试次数也要谨慎斟酌。建议只对消息丢失、错误、丢失特别敏感的时候使用，如果过度使用，反而可能造成请求堆积，队列阻塞。

#### 2 消息服务器处理阶段

- 单节点模式下的Broker，优化Broker参数，在收到消息并持久化到磁盘之后才把确认消息返回给生产者 Producer。下面以RocketMQ为例子介绍配置优化手段：

  如果是RabbitMQ，则将Message的delivermode设置为2，exchange持久化动作操作完成之后才返回确认消息，确保消息不丢失；

  将 flushDiskType 设置为 SYNC_FLUSH，这是同步刷盘的意思，那就要求把这个动作同步完成之后才算消息发送成功。

- 上面说的是单节点模式，如果配置了集群模式，一般是多副本，则要求确认消息要发到 一半以上（N/2 + 1）的节点并得到响应。这样Producer才算真正发送成功。

#### 3 消息消费阶段

消息存储到了Broker之后，剩下的就是消息消费了。消息消费阶段跟生产阶段大概一致，都是使用确认机制来保证消息的可靠性和传输的。
当Consumer从Broker拉取到消息之后，开始消费消息，执行业务的的逻辑程序，业务程序执行成功后，才给Broker发送消费确认响应。
如果没成功或者消息在发送中途丢失，就没有确认响应，这样的话，在下一轮消息拉取的时候，Broker依旧会返回这一条消费数据给你，避免网络抖动原因或者Consumer在执行消费出错导致丢失。

**消息分区的策略模式**

多个消费者消费用一个分区，我们经常会出现这种情况：同一个Consumer Group 里面有多个Consumer，比如Comsumer A 拉走了某一批数据，但是还没返回确认消息，Consumer B 又过来要 拉数据了，Broker要怎么判定呢？
这边举个例子：Consumer A 拉取 index = 106 位置的数据，但是还没返回消费完成的确认信息，这时候消费位置依然是 index = 10086，如果 Consumer B 也过拉取数据，则

- Broker接收确认信息的时间未超时（比如配置为5s），则说明Consumer A还在消费中，回绝了Consumer B的请求。

- Broker接收确认信息的时间已超时（比如配置为5s），则说明Consumer A消费失败了，返回 index = 106 位置的消息数据给 Consumer B。

  所以，多个消费者消费同一个分区，要严格按照顺序消费，具体可以参考官网的介绍，很详细。

**消费重试和死信队列**

在RocketMQ中，当消息第一次消费失败时，消息队列会自动进行消息重试，达到最大重试次数（可配置阈值，比如5）后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息。此时，消息队列RocketMQ版不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中。这种无法被消费的消息称为死信消息（Dead-Letter Message），存储死信消息的特殊队列称为死信队列（Dead-Letter Queue）。
可以使用单独的作业服务进行独立处理，比如重新发送死信消息进行消费，避免消息漏处理导致业务服务可用性问题。



## kafka

页缓存、零拷贝
