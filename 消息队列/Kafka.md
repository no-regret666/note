# Kafka

## 消费者

### 分区再均衡

Rebalance。规定了一个Consumer Group下的所有Consumer如何达成一致，来分配订阅Topic的每个分区。

#### 分区再均衡的过程

1. 选择群主

   第一个加入群组的消费者将成为”群主“。群主会从协调器那里获取群组的活跃成员列表，并负责给每一个消费者分配分区。

   > 协调者：专门为Consumer Group服务，负责为Group执行再均衡以及提供位移管理和组成员管理等。Consumer 端应用程序在提交位移时，其实是向 Coordinator 所在的 Broker 提交位移。同样地，当 Consumer 应用启动时，也是向 Coordinator 所在的 Broker 发送各种请求，然后由 Coordinator 负责执行消费者组的注册、成员管理记录等元数据管理操作。

2. 消费者通过向被指派为群组协调器的Broker定期发送心跳来维持它们和群组的从属关系以及它们对分区的所有权。
3. 群主从群组协调器获取群组成员列表，然后给每一个消费者进行分配分区 Partition。分配策略：
   - Range策略，就是把若干个连续的分区分配给消费者。
   - RoundRoin策略，就是把所有分区逐个分给消费者。
4. 群主分配完成之后，把分配情况发送给群组协调器。
5. 群组协调器再把这些信息发送给消费者。每个消费者只能看到自己的分配信息，只有群主知道所有消费者的分配信息。



### 提交偏移量

更新分区当前消费位置的操作叫做提交。

#### 偏移量的用处

防止消费者崩溃重启时，能读取每个分区最后一次提交的偏移量，然后从偏移量指定的地方继续处理。

1. 如果提交的偏移量小于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息就会被重复处理。
2. 如果提交的偏移量大于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息将会丢失。

### 偏移量管理机制

- 早期是把偏移量保存在ZooKeeper中，但是频繁的提交偏移量操作会拖慢ZooKeeper集群的性能。

- 新版本是向一个叫做 **_consumer_offsets** 的特殊主题发送消息，消息里包含每个分区的偏移量。

  _consumer_offsets 主题的 Key 中应该保存 3 部分内容：<Group ID，主题名，分区号 >。



## 可靠传输

### 消息不丢失

#### 存储阶段

Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。

##### 副本机制

Kafka 的副本机制是 kafka 可靠性保证的核心。



#### 生产阶段

通过请求确认机制来保证消息的可靠传递。

##### ACK

- acks = 1、acks = 1 都有数据丢失的风险
- acks = all 意味着会等待所有同步副本都收到消息

##### 重试

- **可重试错误**，如：LEADER_NOT_AVAILABLE，主副本不可用，可能过一段时间，集群就会选举出新的主副本，重试可以解决问题。
- **不可重试错误**，如：INVALID_CONFIG，即使重试，也无法改变配置选项，重试没有意义。

##### 错误处理

开发者需要自行处理的错误



#### 消费阶段

消费者唯一要做的是确保哪些消息是已经读取过的，哪些是没有读取过的（通过提交偏移量给 Broker 来确认）。如果消费者提交了偏移量却未能处理完消息，那么就有可能造成消息丢失，这也是消费者丢失消息的主要原因。

- 在处理完消息后再发送确认（提交偏移量），不要收到消息立即确认。
- 消费者可能需要维护消费状态，如：处理完消息后，记录在数据库中。



### 重复消费

在 MQTT 协议中，给出了三种传递消息时能够提供的服务质量标准，这三种服务质量从低到高依次是：

- **At most once**：至多一次。消息在传递时，最多会被送达一次。没什么消息可靠性保证，允许丢消息。一般都是一些对消息可靠性要求不太高的监控场景使用。
- **At least once**: 至少一次。消息在传递时，至少会被送达一次。也就是说，不允许丢消息，但是允许有少量重复消息出现。
- **Exactly once**：恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是最高的等级。

绝大部分消息队列提供的服务质量都是 At least once，包括 RocketMQ、RabbitMQ 和 Kafka 都是这样。也就是说，消息队列很难保证消息不重复。

一般解决重复消息的办法是，**在消费端，保证消费消息的操作具备幂等性**。

常用的实现幂等操作的方法：

- 利用数据库的唯一约束实现幂等
- 为更新的数据设置前提条件
- 记录并检查操作



### 消息的有序性

1. 单Partition

   Kafka每一个Partition只能隶属于消费者群组中的一个Consumer，换句话说，每个 Partition 只能被一个 Consumer 消费。所以，如果 Topic 是单 Partition，自然是有序的。

2. 同一个key的消息发送给指定Partition

   （1）生产者端显示指定 key 发往一个指定的 Partition，就可以保证同一个 key 在这个 Partition 中是有序的。

   （2）接下来，消费者端为每个 key 设定一个缓存队列，然后让一个独立线程负责消费指定 key 的队列，这就保证了消费消息也是有序的。



### 消息积压

1. 先修复消费者，然后停掉当前所有消费者
2. 新建Topic，扩大分区，以提高并发处理能力
3. 创建临时消费者程序，并部署在多节点上，扩大消费处理能力
4. 最后处理完积压消息后，恢复原先部署架构。



## Kafka集群

### Kafka和ZooKeeper

**Kafka 使用 Zookeeper 来维护集群成员的信息**。每个 Broker 都有一个唯一标识符，这个标识符可以在配置文件里指定，也可以自动生成。在 Broker 启动的时候，它通过创建临时节点把自己的 ID 注册到 Zookeeper。Kafka 组件订阅 Zookeeper 的 /broker/ids 路径，当有 Broker 加入集群或退出集群时，这些组件就可以获得通知。



### ISR

同步副本。Follower 副本不提供服务，只是定期地异步拉取领导者副本中的数据而已。既然是异步的，说明和 Leader 并非数据强一致性的。

**判断 Follower 是否与 Leader 同步的标准**：

只要一个 Follower 副本落后 Leader 副本的时间不连续超过 10 秒，那么 Kafka 就认为该 Follower 副本与 Leader 是同步的，即使此时 Follower 副本中保存的消息明显少于 Leader 副本中的消息。

ISR 是一个动态调整的集合，会不断将同步副本加入集合，将不同步副本移除集合。Leader 副本天然就在 ISR 中。



### 选举Leader

Kafka 把所有不在 ISR 中的存活副本都称为非同步副本。在 Kafka 中，选举这种副本的过程称为 Unclean 领导者选举。Broker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举。

**开启 Unclean 领导者选举可能会造成数据丢失**，但好处是：它使得 Partition Leader 副本一直存在，不至于停止对外提供服务，因此提升了高可用性。反之，禁止 Unclean 领导者选举的好处在于维护了数据的一致性，避免了消息丢失，但牺牲了高可用性。

